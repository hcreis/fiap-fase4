RELATÓRIO ACADÊMICO - ANÁLISE DE VÍDEO BASEADA EM VISÃO COMPUTACIONAL

1. Objetivo
Este relatório apresenta os resultados de um pipeline automatizado de visão computacional para (i) detecção e marcação de faces, (ii) análise de expressões emocionais, (iii) categorização de atividades com estimativa de pose e (iv) identificação de anomalias.

2. Materiais e Métodos
- Detecção/representação facial: InsightFace (modelo 'buffalo_l') com resolução de identidade online.
- Emoções faciais: modelo ONNX de emoções (inferência por recorte de face; emoção dominante por face).
- Atividades corporais: YOLO Pose (keypoints) com heurísticas para 'EM_PE', 'SENTADO', 'ACENO' e 'APERTO_DE_MAO'.
- Segmentação em cenas: agrupamento por personagem dominante com consistência temporal (histerese e janela mínima).
- Anomalias: (a) persistência de emoções negativas por janela e (b) picos de velocidade (z-score) em keypoints.

3. Resultados
Foram analisados 3326 frames (~110.9 s a 30 fps).

3.1 Atividades predominantes
As atividades mais frequentes, computadas por ocorrência ao longo dos frames, foram: SENTADO (n=551), EM_PE (n=59).

3.2 Emoções predominantes
As emoções mais recorrentes, estimadas por face analisada, foram: neutral (n=4714).

3.3 Eventos sociais (confirmados por janela temporal)
Foram identificados eventos discretos com confirmação temporal, incluindo: APERTO_DE_MAO (n=26).

3.4 Segmentação em cenas
A análise foi organizada em 11 cenas, definidas como intervalos em que um personagem permanece dominante por uma janela mínima, reduzindo fragmentação causada por oscilações momentâneas.

3.5 Anomalias
Foram registradas 0 anomalias associadas a persistência de emoções negativas e 0 anomalias relacionadas a picos de movimento.

4. Discussão e Limitações
A abordagem baseada em heurísticas (ex.: aceno e aperto de mão) depende da qualidade dos keypoints e pode gerar falsos positivos em situações de oclusão, proximidade entre indivíduos e variações de perspectiva. A segmentação temporal por personagem dominante, com janela mínima, melhora a legibilidade do relatório, mas não substitui um algoritmo completo de tracking multiobjeto.

5. Conclusão
O pipeline implementado integra detecção facial, análise emocional e reconhecimento de atividades a partir de pose, produzindo um relatório consolidado por cenas e métricas globais, além de sinalização de anomalias comportamentais.
