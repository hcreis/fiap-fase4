# AnÃ¡lise de VÃ­deo â€” Tech Challenger Fase 4 ğŸ”

**Resumo:** Projeto que processa um vÃ­deo para detectar faces, estimar emoÃ§Ãµes, estimar pose (atividades) e gerar relatÃ³rios por cena. O script principal Ã© `tech_challenger_fase_4.py`.

---

## âœ… Requisitos

- **Python 3.11** (OBRIGATÃ“RIO)
- Sistema operacional: Linux (testado) â€” outras plataformas podem funcionar, ajustes de dependÃªncias podem ser necessÃ¡rios
- **TensorFlow** (necessÃ¡rio para `deepface` â€” instale `tensorflow` ou `tensorflow-cpu` conforme disponÃ­vel)
- EspaÃ§o para modelos e vÃ­deo de entrada

## ğŸ“¦ InstalaÃ§Ã£o

1. Crie e ative um ambiente virtual com Python 3.11 (recomendado):

```bash
python3.11 -m venv .venv
source .venv/bin/activate
```

2. Instale dependÃªncias:

```bash
python -m pip install --upgrade pip
pip install -r requirements.txt
```

> Dica: se ocorrerem erros com bibliotecas C (ex.: OpenCV), verifique que vocÃª tem ferramentas de build e dependÃªncias do sistema instaladas.

## ğŸ—‚ï¸ Arquivos importantes

- `tech_challenger_fase_4.py` â€” script principal
- `requirements.txt` â€” dependÃªncias do projeto
- `yolo11n-pose.pt` â€” modelo YOLO de pose (deve estar no diretÃ³rio do projeto)
- `video_tech_challenger_fase_4.mp4` â€” vÃ­deo de entrada (coloque no diretÃ³rio do projeto)
- `blaze_face_short_range.tflite` â€” arquivo TFLite incluÃ­do no repositÃ³rio

## ğŸ“¥ Modelos necessÃ¡rios

- - EmoÃ§Ãµes: o script usa `DeepFace.analyze` (backend TensorFlow) para estimar emoÃ§Ãµes.
- `yolo11n-pose.pt` â€” modelo de pose usado pelo script; o arquivo `yolo11n-pose.pt` estÃ¡ incluÃ­do no repositÃ³rio atual.
- O InsightFace (`buffalo_l`) Ã© carregado automaticamente pela biblioteca InsightFace (serÃ¡ feito download quando necessÃ¡rio, se houver internet).

## â–¶ï¸ Como executar

Coloque o vÃ­deo de entrada com o nome `video_tech_challenger_fase_4.mp4` na raiz do projeto ou edite o `main()` para apontar para outro arquivo.

Execute:

```bash
python tech_challenger_fase_4.py
```

O script irÃ¡ gerar no mesmo diretÃ³rio:

- `video_tech_challenger_fase_4_final.mp4` â€” vÃ­deo anotado
- `relatorio_final_tecnico.txt` â€” relatÃ³rio tÃ©cnico
- `grafico_emocoes.png` â€” grÃ¡fico com a distribuiÃ§Ã£o de emoÃ§Ãµes (se houver detecÃ§Ãµes)

## âš™ï¸ ConfiguraÃ§Ãµes Ãºteis

No topo de `tech_challenger_fase_4.py` hÃ¡ vÃ¡rias constantes que vocÃª pode adaptar:

- `PULAR_FRAMES` â€” pular frames para acelerar processamento (0 = desativado)
- `LIMIAR_SIMILARIDADE_FACE` â€” quÃ£o rÃ­gida Ã© a fusÃ£o de embeddings faciais
- `MIN_FRAMES_TROCA_CENA` â€” janela mÃ­nima para trocar de cena
- `MIN_FRAMES_PARA_CONFIRMAR` â€” quantos frames para confirmar um aceno

## ğŸ SoluÃ§Ã£o de problemas

- Erro: `NÃ£o foi possÃ­vel abrir o vÃ­deo` â†’ confirme o caminho e o nome do arquivo (`video_tech_challenger_fase_4.mp4`) e codecs.
- Erro relacionado a `yolo11n-pose.pt` â†’ coloque o arquivo correto na raiz ou altere para um checkpoint disponÃ­vel.
- LentidÃ£o / uso alto de CPU â†’ o pipeline roda em CPU (intencional). Para acelerar, use mÃ¡quinas com CPU mais rÃ¡pida ou GPU e adapte os providers do ONNX/InsightFace (requer drivers CUDA e builds compatÃ­veis).
- Projeto testado e valido com CPU.

## ğŸ‘¥ Membros

- Helen de Cassia dos Reis Cruz | RM364533
- Leandro Bernardo dos Santos | RM364501
